
 nginxとunicornとRailsをとりあえず動作することを最優先で設定したので、サーバとしての基本的なパフォーマンスチューニングが何も為されていない。その結果、


 ヤバイ。
 これだと、誰かがツイッターで紹介してくれたりした途端にサーバが沈黙しちゃう。そこで、今回はコードとDB側の改善策を考える。サーバ最適化も同時進行だが、まとめはまた後日に。


#どれだけヤバイのかを、どうやって測定したか。

　先の画面は、負荷測定ツールJMeterで出した統計。使い方についてはこちらの記事が詳しい。


　この記事を読めば最低限の事はすぐにできるが、HTTPヘッダの設定を忘れないようにと申し上げておきたい。ヘッダが空の初期状態のままリクエストし、gzip等が有効にならなくて困った経験から。追加->設定エレメント->HTTPヘッダで設定できる。


#MongoDBのクエリを改善する。

　さて、このサイトでは、ランキングや検索にこんなイテレータを使っている。本物から適宜改変してある。

  @ml = MYLIST_COLL　
    .find(  {"available" => true, "nonpublic" => false}, 
            :sort => [[sort, :desc]])
    .limit(100)
    .map do |e|

      # available == 事前のvalidationに合格してるもの。
      # nonpublic == 投稿者が非公開を希望してるもの。
      
      # part1と最新作を、動画コレクションから探し出す。         
      e['first'] = MOVIE_COLL.find_one({"_id" => e['element']['item_id'].last})
      e['last'] = MOVIE_COLL.find_one({"_id" => e['element']['item_id'].first})

      ...

      # 投稿者ニックネームを、投稿者コレクションから探す。
      e['user_name'] = getUser(e['user_id'])

      e['rank'] = count
      count += 1

      e
    end

　簡単に言うと、

+ マイリストコレクションから、ランキングに載せていいものを検索し、
+ それを指定した順序でソートしたものから上位100件を抽出する。
+ マイリストコレクションに含まれる動画IDの配列を参考に、動画コレクションからPart1と最新作の動画を抽出する。
+ マイリストコレクショントに含まれるユーザIDをもとに、ユーザコレクションを検索して投稿者の名前を抽出する。
+ これらの処理をmapでまとめて、Viewに渡すためのインスタンス変数に入れる。

　こういう構造になっている。


##破壊的メソッドを使う…失敗

　僕は当初、MongoDBのRubyドライバのfindメソッドはHashを返すものと思っていた。が、そうではなく、Enumeratorオブジェクトを返していた。問題は、Enumeratorクラスに破壊的なmap!メソッドが無いこと。ここでmap!が使えれば、もう少し早くなるんじゃないかと思った。
　そこで、map!を使うために一度配列に変換することにする。Enumeratorオブジェクトに、to_aメソッドを適用する。

  mlAry = 
    MYLIST_COLL
      .find( {"available" => true, "nonpublic" => false}, 
             :sort => [[sort, :desc]])
             .limit(100)
             .to_a # <- これ！
           
  mlAry .map! do |e| 
    ...
  end

　…10%程遅くなった。破壊的メソッドの恩恵が配列への変換コストを上回るかと思ったが、そんなことはなかった。次だ次！

##複合インデックスを作り、そのインデックス使用を強制する。

　MongoDBも当然インデックスが使えるので、適当にインデックスを張っていた。次はそれを検証し直す。
　MongoDBには、MySQLと趣旨を同じくするexplainメソッドがある。簡潔だが、クエリの内部処理がどうなっていたかを教えてくれる。MongoDBにおいては、どのインデックスが使われているかが重要になり、そして特定のインデックスの使用を強制する'hint'メソッドがあるらしい。

 まずはexplainをやってみる。
 ランキングページのクエリをMongoDBのJSコンソール的に書き直すとこうなる。

 db.mylist
  .findnd({"available":true, "nonpublic":true})
  .sort({"status.daily.point":1})
  .explain();

　で、これにexplain()を付ける。

 db.mylist
  .findnd({"available":true, "nonpublic":true})
  .sort({"status.daily.point":1})
  .explain();

 そうすると、こんな結果が出る。

{
  "cursor" : "BtreeCursor available_1",
  "nscanned" : 3071,
  "nscannedObjects" : 3071,
  "n" : 3071,
  "scanAndOrder" : true,
  "millis" : 212, <- 遅い！
  "nYields" : 0,
  "nChunkSkips" : 0,
  "isMultiKey" : false,
  "indexOnly" : false,
  "indexBounds" : {
    "available" : [
      [
        true,
        true
      ]
    ]
  }
}

　今回見るべき所は、millisとindexBoundsだと思う。このクエリでは、availableに張ったインデックスのみを使っているが、ソートの事を考えるとstatus.daily.pointへ張られたインデックスが使われていたほうがよさそうな気がする。いやまて、availableとnonpublicは絶対に診るのだから、全てを含んだ複合インデックスの方がいいのだろうか。
　B-Treeがどうとか言う話になると自信がなくなってくるが、とりあえず作ってみることにする。

　作り方。

 db.mylist
  .ensureIndex({"available":true, "nonpublic":true, "status.daily.point":1});

　作った後はhintメソッドをつけて、その複合インデックスの使用を強制してみる。

 db.mylist
  .find({"available":true, "nonpublic":false})
  .sort({"status.daily.point":1})
  .hint({"available":true, "nonpublic":true, "status.daily.point":1})
  .explain()

{
  "cursor" : "BtreeCursor available_1_nonpublic_1_status.daily.point_1",
  "nscanned" : 3071,
  "nscannedObjects" : 3071,
  "n" : 3071,
  "millis" : 5,　　<- 速い！
  "nYields" : 0,
  "nChunkSkips" : 0,
  "isMultiKey" : false,
  "indexOnly" : false,
  "indexBounds" : {
    "available" : [
      [
        true,
        true
      ]
    ],
    "nonpublic" : [
      [
        false,
        false
      ]
    ],
    "status.daily.point" : [
      [
        {
          "$minElement" : 1
        },
        {
          "$maxElement" : 1
        }
      ]
    ]
  }
}

　速くなった。とりあえずコンソール上では。
　ちなみに、hintで強制しなくてもこの複合インデックスが自動選択されるようだ。ただ、availableとnonpublicのみの複合インデックスにしてもあまり違いがなかったが…特に遅くなってもいないので、とりあえずこれで良しとする。

##

　Rubyドライバにおいては、hintメソッドはなく、その代わりfindメソッドのパラメータとして設定するようになっている。こんな感じに。



　しかし…

　速くなってない！！
　本当にちゃんとインデックスが使われてるんだろうか。調べてみると、Rubyドライバにもexplainメソッドがある。そこでこれを表示させてみると、

{
  "cursor"=>"BtreeCursor available_1_nonpublic_1_status.daily.point_1 reverse", 
  "nscanned"=>100, 
  "nscannedObjects"=>100, 
  "n"=>100, 
  "millis"=>15, 
  "nYields"=>0, 
  "nChunkSkips"=>0, 
  "isMultiKey"=>false, 
  "indexOnly"=>false, 
  "indexBounds"=>{
    "available"=>[[true, true]], 
    "nonpublic"=>[[false, false]], 
    "status.daily.point"=>[[{"$maxElement"=>1}, {"$minElement"=>1}]]
  }
}

　うーん、複合インデックスは確かに使われている。ちなみに、db.system.profile.find()を使ってMongoDBコンソールで調べる方法もある。

　そうすると、どうも他にボトルネックがあるらしい。このクエリ自体はとにかく爆速で行われているんだもの。しばし考えたりググったりして、オフィシャルに(http://diigo.com/0kwog)[こういう記事]を見つけた。

　MongoDBはRDBMSにおけるJOIN的な事、つまりあるテーブルの（MongoDBではコレクションの）ある情報を基に、あるテーブルのある情報達を「参照」する機構を標準で備えていない。いないので、必要ならばそういうコードを自分で書いてね、という設計思想らしいが、この記事は「パフォーマンスのためにはできるだけ参照もやめて、最初から埋め込んでくれ」と言っている。

　MongoDBにおける「埋め込み」(Embedded)とは、単純にドキュメントを階層化して目的の情報を下のレイヤーに置くことらしい。埋め込みという特別な仕組みがあるのかと最初僕は思っていたが、そうではないようだ。そして記事の結論を簡単に言うと、「多対多の関係がない限りは、全部最初から1つのドキュメントにぶら下げたほうが、少なくともパフォーマンス上は有利だ」という事のようだ。

　さて、先のコードに話を戻すと、そこでは「参照」を1ドキュメントあたり3回行なっている。つまり、

+ そのシリーズのPart1の動画
+ そのシリーズの最新作の動画
+ 投稿者

　それぞれのドキュメントへの参照を、1つのシリーズマイリスト毎に行なっている。そして、これらとマイリストドキュメントは多対多の関係ではない（マイリスト間でそれぞれが持つ動画は重複しないという前提を保持するように、クローラを設計している）。で、試しにこれら3つの参照をコメントアウトしてみると、


　こんなにパフォーマンスが上がった。

##クローラをEmbedded仕様に改修する。

　そこで、参照を使わずに済むようにDB構造を変える。クローラを公開するのはさすがに抵抗があるので、結論だけ。

　こういう感じで、今まではマイリストと投稿者、動画を別コレクションにしていた。それを、こういう感じにした。



　説明をすると、基本的にマイリストと投稿者と動画コレクションの合体である。ただし、動画のログ部分は逆に分割した。

　合体してもいいという判断の理由としては、基本的に動画とマイリストは多対多の対応ではないことと、投稿者はIDとニックネームという要素しか無く、ニックネームは可変なので、埋め込んでしまって問題ないだろうということ。ニコ動的にはマイリスと動画は多対多だが、ゲームのシリーズのみをまとめたマイリストとしては、ある動画はあるマイリスにのみ属している事が理想であり、そうでないものを排除するようなクローラ設計をしている。

　動画だけを検索したいときにはどうすんだ、という話になるが、その場合は単に動画IDをキーに検索すればいいだけだと思う。もちろんコレクションが巨大になる分、分割時より速度は下がるだろう。ただ、インデックスさえ適切であれば問題にならないはずで、それがドキュメント指向DBの利点でもあるはず。

　ドキュメントを分割するというのは、2つの理由から。
　まず、ログは主に日々のバッチ処理で使い、ランキングページ等のイテレーションには係わらないから。そして、日々のバッチ処理を考えると、速度的に利点のあるcappedコレクションに変える意味があると思ったから。

　cappedドキュメントとは、名前の通り最初からcapされた―容量を制限された特別なドキュメントで、制限されている代わりに読み書きが速いという特徴がある（らしい）。部分削除ができない、容量超過すると古いものが消えるという仕様があり、主にログ用として使われるらしいが、後者のデメリットについては、ドキュメントサイズを十分大きく設定することで予防する。


　
　先のイテレータから参照を省いた。そうすると、


　これだけ速くなった。






##ここでを導入

　しかしどうも、本質的な改善になってない。大体、トップページでも同様のイテレーションを行なっているのに、3倍以上の応答性能がある。そして、そのトップページでさえ3リクエスト/秒が限界なのだ。

　この状況を打開するために、何処がボトルネックになっているのかを見つけるためのツールを導入する。




gzip



Ruby 1.9.3に変える



#サーバの基本設定を行う。

##nginxのproxy cacheを設定する。

 nginx（の少なくとも1.0.6）はproxy cacheがデフォルトで有効らしい。最初はこんなに遅いのはproxy cacheが効いてないからだろうと思っていたが、明示的にオフにしたら更に遅くなってしまった。

 とはいえ、ランキングという動的な要素が大半なので、キャッシュの類はあまり効かないだろうと思っていた。

##gzipを設定する。

　gzipを設定する。このサイトでは、圧縮率は最低の1にした場合が最も速かった。これで10%程度の改善。

##expires等を設定する。


